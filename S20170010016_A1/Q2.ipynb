{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GEVGkvx1WxHz"
   },
   "source": [
    "# Question 2 - Assignment I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fI0Nho7TX6oT"
   },
   "source": [
    "The second problem statement supplies with Human Action Recognition dataset with 7 classes.\n",
    "\n",
    "The task is implemented using a 3-layer Convolutional Neural Network along with 1-Fully Connected Layer for final output. Cross-Entropy Loss function is used to compute the loss and Stochastic Gradient Descent is used as optimizer along with the multi-step Learning rate decay.\n",
    "\n",
    "The code utilizes the PyTorch Deep Learning Framework for implementing and executing the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRUJ4pGUW4Sx"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lo6K20ctL--Z"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1eT3SIfW9t1"
   },
   "source": [
    "### Convolutional Neural Network Definition\n",
    "\n",
    "This is a 3-layer CNN with each sequence comprising of a CNN layer, ReLU activation function and Max-Pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-cFJybi3dk_"
   },
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
    "\n",
    "        #INPUT - 224*224*3\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        #INPUT - 112*112*32\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        #INPUT - 56*56*64\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        #INPUT - 28*28*128\n",
    "        \n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc = nn.Linear(28 * 28 * 128, 7)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PA2E5_PMXDf1"
   },
   "source": [
    "### Train-Test Split Helper Function\n",
    "\n",
    "This function sourced from PyTorch documentation helps in splitting the dataset into train and test. The image size is set at 224 * 224.\n",
    "\n",
    "Change the dataset path according to your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVjCKFwuzHcQ"
   },
   "outputs": [],
   "source": [
    "# Train-Test Split Helper Function\n",
    "def train_test_split(datadir, ratio = .25):\n",
    "  \n",
    "    train_transforms = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "    test_transforms = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "    \n",
    "    train_data = datasets.ImageFolder(datadir, transform = train_transforms)\n",
    "    test_data = datasets.ImageFolder(datadir, transform = test_transforms)\n",
    "    \n",
    "    number_train = len(train_data)\n",
    "    indices = list(range(number_train))\n",
    "    split = int(np.floor(ratio * number_train))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    \n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=64)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=64)\n",
    "    \n",
    "    return trainloader, testloader\n",
    "\n",
    "data_dir = '/content/mydrive/My Drive/Random/HumanActionClassification'\n",
    "trainloader, testloader = train_test_split(data_dir, .25)\n",
    "print(trainloader.dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaoDvdh3XNDz"
   },
   "source": [
    "### Variable Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_S_sreE8dT8"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "num_classes = 7\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = ConvolutionalNeuralNetwork()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5,10,15], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WQVfEG01XSAE"
   },
   "source": [
    "### CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1pteg6yo89Wg"
   },
   "outputs": [],
   "source": [
    "total_step = len(trainloader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  \n",
    "    scheduler.step()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%' .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(), (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBesKh9tXY6a"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rZAt4jJ9kmn"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in testloader:\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy: {} %'.format((correct / total) * 100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
